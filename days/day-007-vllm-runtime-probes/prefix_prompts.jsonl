{"workload":"chat_policy","prefix_regime":"medium","prompt":"SYSTEM: You are a careful assistant. Follow policy.\nPolicy: Always be concise. Never reveal secrets.\nPolicy: If unsure, ask clarifying questions.\n\nConversation so far:\nUser: I manage a GPU inference cluster.\nAssistant: Understood.\n\nQ: What is prefix caching in vLLM?\nA:"}
{"workload":"chat_policy","prefix_regime":"medium","prompt":"SYSTEM: You are a careful assistant. Follow policy.\nPolicy: Always be concise. Never reveal secrets.\nPolicy: If unsure, ask clarifying questions.\n\nConversation so far:\nUser: I manage a GPU inference cluster.\nAssistant: Understood.\n\nQ: Explain TTFT vs end-to-end latency.\nA:"}
{"workload":"chat_policy","prefix_regime":"medium","prompt":"SYSTEM: You are a careful assistant. Follow policy.\nPolicy: Always be concise. Never reveal secrets.\nPolicy: If unsure, ask clarifying questions.\n\nConversation so far:\nUser: I manage a GPU inference cluster.\nAssistant: Understood.\n\nQ: Why does max-model-len affect capacity?\nA:"}
{"workload":"rag_manual","prefix_regime":"large","prompt":"SYSTEM: You answer questions about the following document.\n\nDOCUMENT (excerpt):\n1) vLLM uses continuous batching to improve throughput.\n2) KV cache grows with context length and dominates VRAM.\n3) Prefix caching reuses KV for repeated prefixes.\n4) Tail latency increases sharply near saturation due to queueing.\n5) Keep configs stable for benchmarking.\n\nDOCUMENT (continued):\n1) vLLM uses continuous batching to improve throughput.\n2) KV cache grows with context length and dominates VRAM.\n3) Prefix caching reuses KV for repeated prefixes.\n4) Tail latency increases sharply near saturation due to queueing.\n5) Keep configs stable for benchmarking.\n\nDOCUMENT (continued):\n1) vLLM uses continuous batching to improve throughput.\n2) KV cache grows with context length and dominates VRAM.\n3) Prefix caching reuses KV for repeated prefixes.\n4) Tail latency increases sharply near saturation due to queueing.\n5) Keep configs stable for benchmarking.\n\nQ: Summarize what matters most for TTFT.\nA:"}
{"workload":"rag_manual","prefix_regime":"large","prompt":"SYSTEM: You answer questions about the following document.\n\nDOCUMENT (excerpt):\n1) vLLM uses continuous batching to improve throughput.\n2) KV cache grows with context length and dominates VRAM.\n3) Prefix caching reuses KV for repeated prefixes.\n4) Tail latency increases sharply near saturation due to queueing.\n5) Keep configs stable for benchmarking.\n\nDOCUMENT (continued):\n1) vLLM uses continuous batching to improve throughput.\n2) KV cache grows with context length and dominates VRAM.\n3) Prefix caching reuses KV for repeated prefixes.\n4) Tail latency increases sharply near saturation due to queueing.\n5) Keep configs stable for benchmarking.\n\nDOCUMENT (continued):\n1) vLLM uses continuous batching to improve throughput.\n2) KV cache grows with context length and dominates VRAM.\n3) Prefix caching reuses KV for repeated prefixes.\n4) Tail latency increases sharply near saturation due to queueing.\n5) Keep configs stable for benchmarking.\n\nQ: When would prefix caching not help?\nA:"}
{"workload":"rag_manual","prefix_regime":"large","prompt":"SYSTEM: You answer questions about the following document.\n\nDOCUMENT (excerpt):\n1) vLLM uses continuous batching to improve throughput.\n2) KV cache grows with context length and dominates VRAM.\n3) Prefix caching reuses KV for repeated prefixes.\n4) Tail latency increases sharply near saturation due to queueing.\n5) Keep configs stable for benchmarking.\n\nDOCUMENT (continued):\n1) vLLM uses continuous batching to improve throughput.\n2) KV cache grows with context length and dominates VRAM.\n3) Prefix caching reuses KV for repeated prefixes.\n4) Tail latency increases sharply near saturation due to queueing.\n5) Keep configs stable for benchmarking.\n\nDOCUMENT (continued):\n1) vLLM uses continuous batching to improve throughput.\n2) KV cache grows with context length and dominates VRAM.\n3) Prefix caching reuses KV for repeated prefixes.\n4) Tail latency increases sharply near saturation due to queueing.\n5) Keep configs stable for benchmarking.\n\nQ: What is the trade-off between TTFT and throughput?\nA:"}
